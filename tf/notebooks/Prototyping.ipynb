{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototyping\n",
    "\n",
    "Creates a neural network which evaluates a time series and produce a set of predicted values for the time series\n",
    "Predicted values may be used in a policy to make a trade. This policy may be modeled by simple multiple regression or a neural network.\n",
    "\n",
    "## Data\n",
    "Test data is taken as most recent to avoid lookahead bias. Train data is split into a validation and training set during fitting.\n",
    "\n",
    "\n",
    "## TODO\n",
    "- Convert feature percentages to stdev\n",
    "- Adding VIX as a signal\n",
    "- Adding High/Low as signals\n",
    "- Multiple securities/ aggregate samples\n",
    "- Policy network\n",
    "- Regularization (l2)\n",
    "- Dilated convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6542\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 6,819\n",
      "Trainable params: 6,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import pandas_datareader as pdr\n",
    "from datetime import datetime\n",
    "\n",
    "def from_network(symbol):\n",
    "    return pdr.get_data_yahoo(symbols=symbol, start=datetime(1900, 1, 1))\n",
    "\n",
    "def from_file(symbol):\n",
    "    dataset_path = keras.utils.get_file(\"{}.csv\".format(symbol), \"http://localhost:8000/data/daily/{}.csv\".format(symbol))\n",
    "    column_names = ['Date','Open','High','Low','Close','Adj Close','Volume'] \n",
    "    return pd.read_csv(dataset_path, \n",
    "                              names=column_names, \n",
    "                              dtype={'Close': np.float64,'Open': np.float64,'High': np.float64,'Adj Close': np.float64, 'Volume': np.float64},\n",
    "                              header=0,\n",
    "                              na_values = \"?\", \n",
    "                              comment='\\t',\n",
    "                              sep=\",\",\n",
    "                              skipinitialspace=True)\n",
    "\n",
    "#dataset = raw_dataset.copy()\n",
    "dataset = from_network('SPY')\n",
    "dataset = dataset.sort_values(by=['Date'],ascending=False)\n",
    "\n",
    "dataset_stats = dataset.describe()\n",
    "dataset_stats = dataset_stats.transpose()\n",
    "NUM_INPUT_NEURONS = 64\n",
    "NUM_OUTPUT_NEURONS = 3\n",
    "NUM_SAMPLES = len(dataset)\n",
    "NUM_TEST_SAMPLES = int(.33 * NUM_SAMPLES)\n",
    "#NUM_TEST_SAMPLES = 1000\n",
    "print NUM_SAMPLES\n",
    "# Create features (only close price for now)\n",
    "def convert_to_percentage(old, new):\n",
    "    return (old - new) / old\n",
    "\n",
    "\n",
    "def convert_labels_to_category(labels): \n",
    "    # Simplification - If positive return, 1, else 0\n",
    "    # return map(lambda arr: 1 if arr[0] > 1 else 0, labels)\n",
    "    # rounding simpliciation, 10th of percentage\n",
    "    return map(lambda arr: map(lambda val: round(val,2),arr), labels)\n",
    "\n",
    "def convert_to_train(raw_dataset):\n",
    "    dataset = raw_dataset.copy()\n",
    "    features = []\n",
    "    labels = []\n",
    "    for i in range(5, len(dataset) - NUM_INPUT_NEURONS):\n",
    "\n",
    "        feature_dataset = dataset[i:i+NUM_INPUT_NEURONS].copy()\n",
    "        latest_close = feature_dataset['Close'].iloc[0]\n",
    "        \n",
    "        features.append(\n",
    "            feature_dataset['Close']\n",
    "                .map(lambda current: convert_to_percentage(latest_close, current))\n",
    "                .tolist()\n",
    "        )\n",
    "        labels.append([\n",
    "            dataset['Close'].iloc[i-1] / latest_close, # 1 day trade\n",
    "            dataset['Close'].iloc[i-3] / latest_close, # 3 day trade\n",
    "            dataset['Close'].iloc[i-5] / latest_close, # 5 day trade\n",
    "        ])\n",
    "        \n",
    "    # Without converting labels the precision is hard to determine accuracy. \n",
    "    # Rather than crude 0/1, maybe this can be more sophisticated\n",
    "    labels = convert_labels_to_category(labels)\n",
    "    \n",
    "    return [features,labels]\n",
    "converted_feature_set = convert_to_train(dataset)\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(converted_feature_set[0][0])]),\n",
    "    layers.Dense(32, activation=tf.nn.relu),\n",
    "    layers.Dense(16, activation=tf.nn.relu),\n",
    "    layers.Dense(NUM_OUTPUT_NEURONS)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer='sgd',\n",
    "                metrics=[\n",
    "                    'mae',\n",
    "                #    'accuracy'\n",
    "                ])\n",
    "  return model\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2158\n"
     ]
    }
   ],
   "source": [
    "#len(converted_feature_set[0][0])\n",
    "print NUM_TEST_SAMPLES\n",
    "train_data = np.array(converted_feature_set[0][NUM_TEST_SAMPLES:])\n",
    "train_labels = np.array(converted_feature_set[1][NUM_TEST_SAMPLES:])\n",
    "\n",
    "test_data = np.array(converted_feature_set[0][:NUM_TEST_SAMPLES])\n",
    "test_labels = np.array(converted_feature_set[1][:NUM_TEST_SAMPLES])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.00160514  0.00124843 ... -0.03968251 -0.03415375\n",
      "  -0.04369539]\n",
      " [ 0.         -0.00035728  0.02188279 ... -0.03581638 -0.04537336\n",
      "  -0.04590925]\n",
      " [ 0.          0.02223212  0.02071428 ... -0.04500001 -0.0455357\n",
      "  -0.03937503]\n",
      " ...\n",
      " [ 0.          0.00280309  0.00630583 ... -0.00840926 -0.00911114\n",
      "  -0.00490651]\n",
      " [ 0.          0.00351259  0.00983838 ... -0.01194772 -0.00773127\n",
      "   0.00281097]\n",
      " [ 0.          0.00634809  0.00775852 ... -0.0112835  -0.0007041\n",
      "   0.00141044]]\n",
      "[[1.   0.98 0.96]\n",
      " [1.   1.   0.98]\n",
      " [1.   1.   0.98]\n",
      " ...\n",
      " [1.   1.   1.  ]\n",
      " [1.   1.   1.  ]\n",
      " [1.   1.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print train_data\n",
    "print train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3452 samples, validate on 863 samples\n",
      "Epoch 1/90\n",
      "3452/3452 [==============================] - 0s 46us/step - loss: 5.7767e-04 - mean_absolute_error: 0.0171 - val_loss: 1.7138e-04 - val_mean_absolute_error: 0.0099\n",
      "Epoch 2/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.7687e-04 - mean_absolute_error: 0.0172 - val_loss: 1.6880e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 3/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.7606e-04 - mean_absolute_error: 0.0171 - val_loss: 1.6815e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 4/90\n",
      "3452/3452 [==============================] - 0s 51us/step - loss: 5.7518e-04 - mean_absolute_error: 0.0171 - val_loss: 1.6957e-04 - val_mean_absolute_error: 0.0099\n",
      "Epoch 5/90\n",
      "3452/3452 [==============================] - 0s 56us/step - loss: 5.7455e-04 - mean_absolute_error: 0.0171 - val_loss: 1.6855e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 6/90\n",
      "3452/3452 [==============================] - 0s 48us/step - loss: 5.7362e-04 - mean_absolute_error: 0.0171 - val_loss: 1.6824e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 7/90\n",
      "3452/3452 [==============================] - 0s 52us/step - loss: 5.7268e-04 - mean_absolute_error: 0.0171 - val_loss: 1.6679e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 8/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.7199e-04 - mean_absolute_error: 0.0171 - val_loss: 1.6807e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 9/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.7124e-04 - mean_absolute_error: 0.0171 - val_loss: 1.6723e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 10/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.7047e-04 - mean_absolute_error: 0.0171 - val_loss: 1.6738e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 11/90\n",
      "3452/3452 [==============================] - 0s 45us/step - loss: 5.6975e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6761e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 12/90\n",
      "3452/3452 [==============================] - 0s 45us/step - loss: 5.6914e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6776e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 13/90\n",
      "3452/3452 [==============================] - 0s 49us/step - loss: 5.6846e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6708e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 14/90\n",
      "3452/3452 [==============================] - 0s 46us/step - loss: 5.6782e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6647e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 15/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.6694e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6921e-04 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.6662e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6732e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 17/90\n",
      "3452/3452 [==============================] - 0s 49us/step - loss: 5.6589e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6606e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 18/90\n",
      "3452/3452 [==============================] - 0s 54us/step - loss: 5.6516e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6716e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 19/90\n",
      "3452/3452 [==============================] - 0s 47us/step - loss: 5.6469e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6685e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 20/90\n",
      "3452/3452 [==============================] - 0s 46us/step - loss: 5.6401e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6653e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 21/90\n",
      "3452/3452 [==============================] - 0s 47us/step - loss: 5.6343e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6695e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 22/90\n",
      "3452/3452 [==============================] - 0s 46us/step - loss: 5.6268e-04 - mean_absolute_error: 0.0170 - val_loss: 1.6319e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 23/90\n",
      "3452/3452 [==============================] - 0s 46us/step - loss: 5.6236e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6451e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 24/90\n",
      "3452/3452 [==============================] - 0s 52us/step - loss: 5.6166e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6334e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 25/90\n",
      "3452/3452 [==============================] - 0s 50us/step - loss: 5.6123e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6579e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 26/90\n",
      "3452/3452 [==============================] - 0s 47us/step - loss: 5.6058e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6621e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 27/90\n",
      "3452/3452 [==============================] - 0s 47us/step - loss: 5.5996e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6484e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 28/90\n",
      "3452/3452 [==============================] - 0s 46us/step - loss: 5.5950e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6508e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 29/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.5896e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6398e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 30/90\n",
      "3452/3452 [==============================] - 0s 50us/step - loss: 5.5825e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6613e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 31/90\n",
      "3452/3452 [==============================] - 0s 49us/step - loss: 5.5790e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6404e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 32/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.5735e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6419e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 33/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.5680e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6335e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 34/90\n",
      "3452/3452 [==============================] - 0s 46us/step - loss: 5.5637e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6242e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 35/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.5593e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6362e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 36/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.5544e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6424e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 37/90\n",
      "3452/3452 [==============================] - 0s 41us/step - loss: 5.5484e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6174e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 38/90\n",
      "3452/3452 [==============================] - 0s 47us/step - loss: 5.5452e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6265e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 39/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.5399e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6430e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 40/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.5356e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6320e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 41/90\n",
      "3452/3452 [==============================] - 0s 41us/step - loss: 5.5304e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6352e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 42/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.5271e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6325e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 43/90\n",
      "3452/3452 [==============================] - 0s 58us/step - loss: 5.5232e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6284e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 44/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.5183e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6277e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 45/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.5137e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6294e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 46/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.5099e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6385e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 47/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.5060e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6203e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 48/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.5020e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6302e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 49/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.4961e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6241e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 50/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.4939e-04 - mean_absolute_error: 0.0168 - val_loss: 1.6083e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 51/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.4902e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6151e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 52/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.4857e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6271e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 53/90\n",
      "3452/3452 [==============================] - 0s 41us/step - loss: 5.4830e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6091e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 54/90\n",
      "3452/3452 [==============================] - 0s 40us/step - loss: 5.4796e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6106e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 55/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.4750e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6218e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 56/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.4713e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6034e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 57/90\n",
      "3452/3452 [==============================] - 0s 45us/step - loss: 5.4686e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6273e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 58/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.4663e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6158e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 59/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.4614e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6009e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 60/90\n",
      "3452/3452 [==============================] - 0s 41us/step - loss: 5.4586e-04 - mean_absolute_error: 0.0167 - val_loss: 1.5939e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 61/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.4554e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6106e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 62/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.4520e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6032e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 63/90\n",
      "3452/3452 [==============================] - 0s 40us/step - loss: 5.4466e-04 - mean_absolute_error: 0.0167 - val_loss: 1.5915e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 64/90\n",
      "3452/3452 [==============================] - 0s 44us/step - loss: 5.4449e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6041e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 65/90\n",
      "3452/3452 [==============================] - 0s 41us/step - loss: 5.4417e-04 - mean_absolute_error: 0.0167 - val_loss: 1.6063e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 66/90\n",
      "3452/3452 [==============================] - 0s 41us/step - loss: 5.4368e-04 - mean_absolute_error: 0.0167 - val_loss: 1.5905e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 67/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.4351e-04 - mean_absolute_error: 0.0167 - val_loss: 1.5955e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 68/90\n",
      "3452/3452 [==============================] - 0s 40us/step - loss: 5.4298e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5859e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 69/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.4295e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5888e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 70/90\n",
      "3452/3452 [==============================] - 0s 41us/step - loss: 5.4254e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5900e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 71/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.4226e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5929e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 72/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.4197e-04 - mean_absolute_error: 0.0166 - val_loss: 1.6099e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 73/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.4148e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5819e-04 - val_mean_absolute_error: 0.0094\n",
      "Epoch 74/90\n",
      "3452/3452 [==============================] - 0s 40us/step - loss: 5.4145e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5793e-04 - val_mean_absolute_error: 0.0094\n",
      "Epoch 75/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.4111e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5851e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 76/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.4067e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5989e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 77/90\n",
      "3452/3452 [==============================] - 0s 43us/step - loss: 5.4055e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5929e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 78/90\n",
      "3452/3452 [==============================] - 0s 51us/step - loss: 5.4014e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5875e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 79/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.3965e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5733e-04 - val_mean_absolute_error: 0.0094\n",
      "Epoch 80/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.3941e-04 - mean_absolute_error: 0.0166 - val_loss: 1.6070e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 81/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.3933e-04 - mean_absolute_error: 0.0166 - val_loss: 1.6062e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 82/90\n",
      "3452/3452 [==============================] - 0s 42us/step - loss: 5.3902e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5848e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 83/90\n",
      "3452/3452 [==============================] - 0s 48us/step - loss: 5.3870e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5940e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 84/90\n",
      "3452/3452 [==============================] - 0s 47us/step - loss: 5.3831e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5712e-04 - val_mean_absolute_error: 0.0094\n",
      "Epoch 85/90\n",
      "3452/3452 [==============================] - 0s 46us/step - loss: 5.3823e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5851e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 86/90\n",
      "3452/3452 [==============================] - 0s 45us/step - loss: 5.3787e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5878e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 87/90\n",
      "3452/3452 [==============================] - 0s 51us/step - loss: 5.3748e-04 - mean_absolute_error: 0.0165 - val_loss: 1.6013e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 88/90\n",
      "3452/3452 [==============================] - 0s 47us/step - loss: 5.3741e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5879e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 89/90\n",
      "3452/3452 [==============================] - 0s 60us/step - loss: 5.3712e-04 - mean_absolute_error: 0.0166 - val_loss: 1.5860e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 90/90\n",
      "3452/3452 [==============================] - 0s 45us/step - loss: 5.3689e-04 - mean_absolute_error: 0.0165 - val_loss: 1.5796e-04 - val_mean_absolute_error: 0.0094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=80, validation_split = 0.2, verbose=1,\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one day return\n",
    "actual = map(lambda arr: arr[0],outputs)\n",
    "# signal step for our policy network\n",
    "signals = map(lambda arr: sum(arr) / len(arr),outputs)\n",
    "# primitive policy temporarily in place of a RL policy network\n",
    "trades = map(lambda signal: 1 if round(signal,2) > 1 else 0,signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'signal':signals,\n",
    "    'actual': actual,\n",
    "    'trade':trades,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['entry_success'] = df.apply (lambda row: 1 if (row['actual'] > 1.00 and row['trade'] == 1) else 0,axis=1)\n",
    "df['entry_failure'] = df.apply (lambda row: 1 if (row['actual'] < 1.00 and row['trade'] == 1) else 0,axis=1)\n",
    "df['avoid_success'] = df.apply (lambda row: 1 if (row['actual'] < 1.00 and row['trade'] == 0) else 0,axis=1)\n",
    "df['avoid_failure'] = df.apply (lambda row: 1 if (row['actual'] > 1.00 and row['trade'] == 0) else 0,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>signal</th>\n",
       "      <th>trade</th>\n",
       "      <th>entry_success</th>\n",
       "      <th>entry_failure</th>\n",
       "      <th>avoid_success</th>\n",
       "      <th>avoid_failure</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994061</td>\n",
       "      <td>1.001055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.005111</td>\n",
       "      <td>1.005983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.001842</td>\n",
       "      <td>1.006654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.001131</td>\n",
       "      <td>1.001591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.982471</td>\n",
       "      <td>0.992030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.993998</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.979161</td>\n",
       "      <td>0.994006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.986842</td>\n",
       "      <td>1.004810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.984634</td>\n",
       "      <td>1.005040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.983880</td>\n",
       "      <td>1.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.983654</td>\n",
       "      <td>0.998688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.996146</td>\n",
       "      <td>1.002032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.010890</td>\n",
       "      <td>1.003333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.007792</td>\n",
       "      <td>1.009979</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.005676</td>\n",
       "      <td>1.009828</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.998402</td>\n",
       "      <td>1.005774</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.999348</td>\n",
       "      <td>1.008372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.998831</td>\n",
       "      <td>1.007289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.002540</td>\n",
       "      <td>1.006061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.997770</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.998139</td>\n",
       "      <td>0.996186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.002607</td>\n",
       "      <td>0.997032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.006129</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.012856</td>\n",
       "      <td>1.004040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.023838</td>\n",
       "      <td>1.010765</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.010608</td>\n",
       "      <td>1.000837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.011873</td>\n",
       "      <td>1.003251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.004611</td>\n",
       "      <td>1.000299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.004393</td>\n",
       "      <td>1.002370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.997983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>0.992080</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>0.983467</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.996683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>0.995184</td>\n",
       "      <td>0.998479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>0.989210</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>0.971783</td>\n",
       "      <td>0.986234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.993805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>0.988688</td>\n",
       "      <td>0.988738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>1.010582</td>\n",
       "      <td>1.000903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>1.012782</td>\n",
       "      <td>1.009378</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>0.996801</td>\n",
       "      <td>0.995987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>0.990950</td>\n",
       "      <td>1.000488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>0.997426</td>\n",
       "      <td>0.998216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>1.009964</td>\n",
       "      <td>1.009983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>1.003106</td>\n",
       "      <td>1.001664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>1.007527</td>\n",
       "      <td>1.008214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>1.001625</td>\n",
       "      <td>0.995303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>0.998354</td>\n",
       "      <td>0.995158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>1.005370</td>\n",
       "      <td>1.005447</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>1.008131</td>\n",
       "      <td>1.007056</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>1.014291</td>\n",
       "      <td>1.006048</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>1.010812</td>\n",
       "      <td>1.003109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>1.003418</td>\n",
       "      <td>1.003829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>1.006695</td>\n",
       "      <td>1.002359</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>1.009913</td>\n",
       "      <td>1.000700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.998257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>0.989476</td>\n",
       "      <td>0.991886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>0.995408</td>\n",
       "      <td>0.991080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>0.990765</td>\n",
       "      <td>0.990698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2158 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual    signal  trade  entry_success  entry_failure  avoid_success  \\\n",
       "0     0.994061  1.001055      0              0              0              1   \n",
       "1     1.005111  1.005983      1              1              0              0   \n",
       "2     1.001842  1.006654      1              1              0              0   \n",
       "3     1.001131  1.001591      0              0              0              0   \n",
       "4     0.982471  0.992030      0              0              0              1   \n",
       "5     0.993998  0.997984      0              0              0              1   \n",
       "6     0.979161  0.994006      0              0              0              1   \n",
       "7     0.986842  1.004810      0              0              0              1   \n",
       "8     0.984634  1.005040      1              0              1              0   \n",
       "9     0.983880  1.000018      0              0              0              1   \n",
       "10    0.983654  0.998688      0              0              0              1   \n",
       "11    0.996146  1.002032      0              0              0              1   \n",
       "12    1.010890  1.003333      0              0              0              0   \n",
       "13    1.007792  1.009979      1              1              0              0   \n",
       "14    1.005676  1.009828      1              1              0              0   \n",
       "15    0.998402  1.005774      1              0              1              0   \n",
       "16    0.999348  1.008372      1              0              1              0   \n",
       "17    0.998831  1.007289      1              0              1              0   \n",
       "18    1.002540  1.006061      1              1              0              0   \n",
       "19    0.997770  0.997613      0              0              0              1   \n",
       "20    0.998139  0.996186      0              0              0              1   \n",
       "21    1.002607  0.997032      0              0              0              0   \n",
       "22    1.006129  0.998924      0              0              0              0   \n",
       "23    1.012856  1.004040      0              0              0              0   \n",
       "24    1.023838  1.010765      1              1              0              0   \n",
       "25    1.010608  1.000837      0              0              0              0   \n",
       "26    1.011873  1.003251      0              0              0              0   \n",
       "27    0.997554  0.996948      0              0              0              1   \n",
       "28    1.004611  1.000299      0              0              0              0   \n",
       "29    1.004393  1.002370      0              0              0              0   \n",
       "...        ...       ...    ...            ...            ...            ...   \n",
       "2128  0.993952  0.997983      0              0              0              1   \n",
       "2129  0.992080  0.999876      0              0              0              1   \n",
       "2130  0.983467  0.993547      0              0              0              1   \n",
       "2131  0.994965  0.996683      0              0              0              1   \n",
       "2132  0.995184  0.998479      0              0              0              1   \n",
       "2133  0.989210  0.996171      0              0              0              1   \n",
       "2134  0.971783  0.986234      0              0              0              1   \n",
       "2135  0.991597  0.993805      0              0              0              1   \n",
       "2136  0.988688  0.988738      0              0              0              1   \n",
       "2137  1.010582  1.000903      0              0              0              0   \n",
       "2138  1.012782  1.009378      1              1              0              0   \n",
       "2139  0.996801  0.995987      0              0              0              1   \n",
       "2140  0.990950  1.000488      0              0              0              1   \n",
       "2141  0.997426  0.998216      0              0              0              1   \n",
       "2142  1.009964  1.009983      1              1              0              0   \n",
       "2143  1.003106  1.001664      0              0              0              0   \n",
       "2144  1.007527  1.008214      1              1              0              0   \n",
       "2145  1.001625  0.995303      0              0              0              0   \n",
       "2146  0.998354  0.995158      0              0              0              1   \n",
       "2147  1.005370  1.005447      1              1              0              0   \n",
       "2148  1.008131  1.007056      1              1              0              0   \n",
       "2149  1.014291  1.006048      1              1              0              0   \n",
       "2150  1.010812  1.003109      0              0              0              0   \n",
       "2151  1.003418  1.003829      0              0              0              0   \n",
       "2152  1.006695  1.002359      0              0              0              0   \n",
       "2153  1.009913  1.000700      0              0              0              0   \n",
       "2154  0.999518  0.998257      0              0              0              1   \n",
       "2155  0.989476  0.991886      0              0              0              1   \n",
       "2156  0.995408  0.991080      0              0              0              1   \n",
       "2157  0.990765  0.990698      0              0              0              1   \n",
       "\n",
       "      avoid_failure  success  \n",
       "0                 0        1  \n",
       "1                 0        1  \n",
       "2                 0        1  \n",
       "3                 1        1  \n",
       "4                 0        1  \n",
       "5                 0        1  \n",
       "6                 0        1  \n",
       "7                 0        1  \n",
       "8                 0        0  \n",
       "9                 0        1  \n",
       "10                0        1  \n",
       "11                0        1  \n",
       "12                1        1  \n",
       "13                0        1  \n",
       "14                0        1  \n",
       "15                0        0  \n",
       "16                0        0  \n",
       "17                0        0  \n",
       "18                0        1  \n",
       "19                0        1  \n",
       "20                0        1  \n",
       "21                1        1  \n",
       "22                1        1  \n",
       "23                1        1  \n",
       "24                0        1  \n",
       "25                1        1  \n",
       "26                1        1  \n",
       "27                0        1  \n",
       "28                1        1  \n",
       "29                1        1  \n",
       "...             ...      ...  \n",
       "2128              0        1  \n",
       "2129              0        1  \n",
       "2130              0        1  \n",
       "2131              0        1  \n",
       "2132              0        1  \n",
       "2133              0        1  \n",
       "2134              0        1  \n",
       "2135              0        1  \n",
       "2136              0        1  \n",
       "2137              1        1  \n",
       "2138              0        1  \n",
       "2139              0        1  \n",
       "2140              0        1  \n",
       "2141              0        1  \n",
       "2142              0        1  \n",
       "2143              1        1  \n",
       "2144              0        1  \n",
       "2145              1        1  \n",
       "2146              0        1  \n",
       "2147              0        1  \n",
       "2148              0        1  \n",
       "2149              0        1  \n",
       "2150              1        1  \n",
       "2151              1        1  \n",
       "2152              1        1  \n",
       "2153              1        1  \n",
       "2154              0        1  \n",
       "2155              0        1  \n",
       "2156              0        1  \n",
       "2157              0        1  \n",
       "\n",
       "[2158 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# primitive policy - replace with a policy network which maximizes reward\n",
    "def label_success (row):\n",
    "    return 0 if (row['entry_failure'] == 1 or row['entry_failure'] == 1) else 1\n",
    "\n",
    "success = df.apply (lambda row: label_success (row),axis=1)\n",
    "df['success'] = success;\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-loss events\n",
      "2128\n",
      "0.98609823911\n",
      "\n",
      "Lose trades\n",
      "30\n",
      "0.0139017608897\n",
      "\n",
      "Win trades\n",
      "198\n",
      "0.0917516218721\n",
      "\n",
      "Missed opportunities\n",
      "707\n",
      "0.327618164968\n",
      "\n",
      "Bullets dodged\n",
      "1223\n",
      "0.566728452271\n"
     ]
    }
   ],
   "source": [
    "print '\\nNon-loss events'\n",
    "print sum(df['success'])\n",
    "print sum(df['success']) / (NUM_TEST_SAMPLES * 1.00)\n",
    "\n",
    "print '\\nLose trades'\n",
    "print sum(df['entry_failure'])\n",
    "print sum(df['entry_failure']) / (NUM_TEST_SAMPLES * 1.00)\n",
    "\n",
    "print '\\nWin trades'\n",
    "print sum(df['entry_success'])\n",
    "print sum(df['entry_success']) / (NUM_TEST_SAMPLES * 1.00)\n",
    "\n",
    "print '\\nMissed opportunities'\n",
    "print sum(df['avoid_failure'])\n",
    "print sum(df['avoid_failure']) / (NUM_TEST_SAMPLES * 1.00)\n",
    "\n",
    "print '\\nBullets dodged'\n",
    "print sum(df['avoid_success'])\n",
    "print sum(df['avoid_success']) / (NUM_TEST_SAMPLES * 1.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
